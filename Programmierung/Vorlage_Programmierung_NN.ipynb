{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Do2bD9ItLotg"
      },
      "source": [
        "# 0. Imports  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fLmW436Loth",
        "outputId": "cdd826fd-ae1f-4598-cdf0-0a0d5afc1a60"
      },
      "outputs": [],
      "source": [
        "# Zunächst werden die erforderlichen Bibliotheken importiert.\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import layers\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import platform\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.utils import plot_model\n",
        "from PIL import Image\n",
        "from datetime import datetime\n",
        "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Prüfen ob das Notebook lokal oder in Google Colab läuft\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "# Download Utility Function if in Colab\n",
        "if IN_COLAB:\n",
        "  url = \"https://seafile.cloud.uni-hannover.de/f/c185fc5036564611999d/?dl=1\"\n",
        "  filename = \"Utility_Functions.zip\"\n",
        "  !curl $url -o $filename -J -L\n",
        "  !unzip -o -q $filename\n",
        "\n",
        "\n",
        "from Utility_Functions.MLL_Callback_Functions import PlotHistoryAndExport, log_confusion_matrix, Conv_Resolution #Custom MLL Callback Functions\n",
        "\n",
        "# Prüfen ob Tensorflow für das Training Zugriff auf die GPU hat.\n",
        "if not IN_COLAB:\n",
        "  pysical_devices = tf.config.list_physical_devices(\"GPU\")\n",
        "  tf.config.experimental.set_memory_growth(pysical_devices[0],True)\n",
        "\n",
        "print('Python version:', platform.python_version())\n",
        "print('Tensorflow version:', tf.__version__)\n",
        "print('Keras version:', keras.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pl6GkAjLoth"
      },
      "source": [
        "# 1. Laden des Datensatzes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yd0abTvLoth",
        "outputId": "62eecc63-02ff-45e2-a4ee-c5c9a5a87fd2"
      },
      "outputs": [],
      "source": [
        "# Die Variable DeinNachname wird verwendet, um Plots, Daten und die neuronalen Netze unter individuellen Namen zu speichern.\n",
        "DeinNachname = \"Dein_Nachname\"           # Hier deinen Nachnamen eintragen\n",
        "\n",
        "# Prüfen ob das Notebook lokal oder in Google Colab läuft\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "  print(\"IN_COLAB\")\n",
        "  url = \"https://seafile.cloud.uni-hannover.de/f/51e1b4397ea444488ae0/?dl=1\"\n",
        "  # Manuelles Festlegen der Archivnamens, da SeaFile diesen nicht mit dem Downloadlink gibt\n",
        "  DownloadFilename = \"match_MLL_dataset_1280.zip\"\n",
        "  DownloadFoldername = \"match_MLL_dataset_1280\"\n",
        "  DatasetDirectory = os.path.abspath(DownloadFoldername)\n",
        "  print(f\"Dataset Directory: {DatasetDirectory}\")\n",
        "  DownloadDataset = True\n",
        "\n",
        "  if os.path.exists(DatasetDirectory):\n",
        "    overwrite = input(f\"Folder {DownloadFoldername} already exists. Overwrite? [y/N]\")\n",
        "    if not overwrite in [\"y\", \"Y\"]:\n",
        "      DownloadDataset = False\n",
        "\n",
        "  if DownloadDataset:\n",
        "    # Datesatz herunterladen:\n",
        "    # os.system(f\"curl {url} -o {filename}\")\n",
        "    # Command direkt in Colab ausführen für bessere Ausgabe\n",
        "    !curl -L $url -o $DownloadFilename\n",
        "    print(\"Download complete\")\n",
        "    # Archiv entpacken:\n",
        "    # os.system(f\"unzip -o {filename}\")\n",
        "    # Command direkt in Colab ausführen für bessere Ausgabe\n",
        "    !unzip -o -q $DownloadFilename\n",
        "    print(\"Dataset extracted successfully\")\n",
        "\n",
        "  Directory = os.path.abspath(DownloadFoldername)\n",
        "\n",
        "\n",
        "else:\n",
        "  Directory = r'Z:\\Datensatz_Archiv\\Random_III_AlleKlassen'  # hier den Pfad für den Datensatz angeben\n",
        "\n",
        "print(f\"Directory: {Directory}\")\n",
        "# Float zwischen 0 und 1, Anteil der Daten, die für die Validierung reserviert werden sollen.\n",
        "Split=0.2                           # hier den Split festlegen\n",
        "\n",
        "# Die Bilder in unserem Datensatz haben eine Originalgröße bzw. Auflösung von (1536,2048)\n",
        "# Um die Speichernutzung effizienter zu gestalten, werden wir die Bilder direkt mit reduzierter Auflösung laden,\n",
        "# anstatt die Bilder mit der Originalauflösung zu laden und diese dann zu reduzieren.\n",
        "Reduced_Image_Size = [360,480]      # (Höhe, Breite)\n",
        "\n",
        "\n",
        "# Zunächst werden die Daten angeben, welche bezüglich des überlegten Bildausschnitts relevant sind.\n",
        "offset_width_GUI = 870           # Startpunkt x-Koordinate\n",
        "offset_height_GUI = 110          # Startpunkt y-Koordinate\n",
        "target_size_GUI = (2450,2450)   # (target_height, target_width), die Größe des Bildausschnitts\n",
        "\n",
        "# Diese werden umgerechnet relativ zu der Göße, mit welcher die Bilder geladen werden sollen.\n",
        "offset_height = Conv_Resolution(Reduced_Image_Size,offset_height_GUI)         # Startpunkt y-Koordinate\n",
        "offset_width = Conv_Resolution(Reduced_Image_Size,offset_width_GUI)           # Startpunkt x-Koordinate\n",
        "target_size = (Conv_Resolution(Reduced_Image_Size,target_size_GUI[0]),Conv_Resolution(Reduced_Image_Size,target_size_GUI[1]))   # (target_height, target_width), die Größe des Bildausschnitts\n",
        "\n",
        "# Die Input_Image_Shape wird später verwendet, um die Eingabeform für die erste Faltungsschicht zu definieren.\n",
        "# \"size\" definiert nur die Höhe und die Breite.\n",
        "# \"shape\" hat zusätzlich die Anzahl an Farbkanälen (3 für RGB, 1 für Greyscale).\n",
        "# Der abgeschnittene Teil des Bildes wird als Eingabe verwendet.\n",
        "# Input_Image_Shape = (target_size[0], target_size[1], 3)\n",
        "Input_Image_Shape = (224, 224, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIuPeu-NLoti",
        "outputId": "83e5ba47-8d2a-4727-99a8-cd7dffcbe9c7"
      },
      "outputs": [],
      "source": [
        "# Jetzt laden wir den Datensatz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTPRxokzLoti"
      },
      "source": [
        "# 2. Formating, Cropping and Resizeing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mWCHH0SLoti"
      },
      "outputs": [],
      "source": [
        "# Hier soll eine Funktion definiert werden, die die Pixelwerte eines Bildes in Floats zwischen 0 und 1 umwandelt\n",
        "# und das Bild auf die gewünschte Größe, wie oben definiert, zuschneidet.\n",
        "# Hinweis 1: Die Funktion format_example im Tutorial macht fast das, was wir wollen.\n",
        "# Der Unterschied besteht darin, dass wir nicht die Größe des Bildes reduzieren, sondern einen Teil des Bildes zuschneiden wollen.\n",
        "# Hinweis 2: google tf.image.crop_to_bounding_box()\n",
        "# vergiss nicht, die Funktion map() zu verwenden, um die Formatierung auf alle Bilder des Datensatzes anzuwenden."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQOeIq5FLotj"
      },
      "source": [
        "# 3. Image-Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SppuppecLotj"
      },
      "outputs": [],
      "source": [
        "# Hier sollten die Funktionen zur Data-Augmentation definiert werden."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2uEBrR8Lotk"
      },
      "source": [
        "# 4. Show Pictures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "624Q3HQeLotk",
        "outputId": "39657da1-eb28-408d-db3a-10d837e627c8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTYOTp0tLotl"
      },
      "source": [
        "# 5. Shuffle and Batching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHUGfjb2Lotl"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 30  # Hier wird die Batchgröße festgelegt    #Default 30"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCVaPWqPLotl"
      },
      "source": [
        "# 6. Create Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "-YVyJVRzLotl",
        "outputId": "058f15c7-3065-4f63-bc57-792b3c47266d"
      },
      "outputs": [],
      "source": [
        "# Erstellt ein neues Sequenzielles Modell mit dem Variablenname \"model\"\n",
        "model = keras.Sequential()\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRmT8EuaLotm"
      },
      "source": [
        "# 7. Compile Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o800VBx_Lotm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aeh09TOrLotm"
      },
      "source": [
        "# 8. Callbacks - Trainingshistorie und Confusion-Matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "X7-dc4K-Lotm",
        "outputId": "73f7e8dc-9d4e-4bab-96f4-985af67c6b00"
      },
      "outputs": [],
      "source": [
        "# Hier definieren, falls abweicht!!\n",
        "######\n",
        "Modellname = model  # Hier Modellobjektnamen angeben\n",
        "Validationset = dataset_test_shuffled  # Ihr den Validationsdatensatz angeben\n",
        "#######\n",
        "\n",
        "NAME_der_LogDatei = \"Neuronales_Netz_{}\".format(\n",
        "    datetime.now().strftime(\"%Y%m%d-%H_%M_%S\")\n",
        ")  # Hier wird der Name der Logdatein definiert\n",
        "\n",
        "if IN_COLAB:\n",
        "    TensorBoard_Log_Image_PATH = \"logs/{}/{}/Image_{}\".format(\n",
        "        DeinNachname, NAME_der_LogDatei, NAME_der_LogDatei\n",
        "    )\n",
        "    TensorBoard_Log_Train_History_PATH = \"logs/{}/{}\".format(\n",
        "        DeinNachname, NAME_der_LogDatei\n",
        "    )\n",
        "else:\n",
        "    TensorBoard_Log_Image_PATH = \"Z:/Programmierung_NN/logs/{}/{}/Image_{}\".format(\n",
        "        DeinNachname, NAME_der_LogDatei, NAME_der_LogDatei\n",
        "    )\n",
        "    TensorBoard_Log_Train_History_PATH = \"Z:/Programmierung_NN/logs/{}/{}\".format(\n",
        "        DeinNachname, NAME_der_LogDatei\n",
        "    )\n",
        "\n",
        "TensorBoard_callback_Train_History = TensorBoard(\n",
        "    log_dir=TensorBoard_Log_Train_History_PATH\n",
        ")\n",
        "\n",
        "file_writer_cm = tf.summary.create_file_writer(TensorBoard_Log_Image_PATH)\n",
        "\n",
        "\n",
        "class MLLCallbacks(keras.callbacks.Callback):\n",
        "    def on_train_end(self, logs=None):\n",
        "        PlotHistoryAndExport(TensorBoard_Log_Train_History_PATH)\n",
        "        model = tf.keras.models.load_model(\n",
        "            TensorBoard_Log_Train_History_PATH + \"/Best_model.h5\"\n",
        "        )\n",
        "        log_confusion_matrix(\n",
        "            None,\n",
        "            Validationset,\n",
        "            model,\n",
        "            class_names,\n",
        "            file_writer_cm,\n",
        "            TensorBoard_Log_Train_History_PATH,\n",
        "            logs,\n",
        "            \"yes\",\n",
        "        )\n",
        "        # log_confusion_matrix(None,Validationset, Modellname, class_names, file_writer_cm, TensorBoard_Log_Train_History_PATH, logs,'yes')\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if (epoch % 1) == 0:\n",
        "            log_confusion_matrix(\n",
        "                epoch,\n",
        "                Validationset,\n",
        "                Modellname,\n",
        "                class_names,\n",
        "                file_writer_cm,\n",
        "                TensorBoard_Log_Train_History_PATH,\n",
        "                logs,\n",
        "                \"no\",\n",
        "            )\n",
        "\n",
        "\n",
        "# stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',min_delta=0,patience=0,verbose=0,mode='auto',baseline=None,restore_best_weights=False)\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    TensorBoard_Log_Train_History_PATH + \"/Best_model.h5\",\n",
        "    monitor=\"val_loss\",\n",
        "    save_best_only=True,\n",
        ")\n",
        "\n",
        "# Funktion zum Plotten von Netzstrukturen.\n",
        "# Das Bild wird auch gespeichert.\n",
        "# Für verschiedene Modelle den Wert des Parameters to_file anpassen. Bsp.: f'{DeinNachname}_1.png'\n",
        "plot_model(\n",
        "    model,\n",
        "    to_file=f\"{TensorBoard_Log_Train_History_PATH}/{DeinNachname}.png\",\n",
        "    show_shapes=True,\n",
        "    show_layer_names=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zc1lTu2hLotm"
      },
      "source": [
        "# 9. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qW_gWIJELotm",
        "outputId": "02ed9331-be51-4a55-b8b1-343b6325147f"
      },
      "outputs": [],
      "source": [
        "train_epoches = 20  # Festlegen der Trainingsepochen\n",
        "\n",
        "# Die Funktion fit() mit den benötigten Parametern anpassen.\n",
        "# Den Parameter callbacks nicht löschen wenn local trainiert wird.\n",
        "# Bei Ausführung in Colab kann der Parameter callbacks gelöscht/auskommentiert werden.\n",
        "# Durch den langsmaen file i/o speed auf colab verlangsamt dieser das Training erheblich.\n",
        "training_history = model.fit(\n",
        "    x=dataset_train_augmented_shuffled.repeat(),  # Festlegen des Trainingsdatensets\n",
        "    validation_data=dataset_test_shuffled.repeat(),  # Festlegen des Validationdatensets\n",
        "    epochs=train_epoches,\n",
        "    steps_per_epoch=steps_per_epoch,  # Muss nur definiert werden, wenn dataset.repeat() in fit() verwendet wird, damit der Trainingsalgorithmus eine Stop Condition hat.\n",
        "    validation_steps=validation_steps,  # Muss nur definiert werden, wenn dataset.repeat() in fit() verwendet wird\n",
        "    verbose=1,\n",
        "    callbacks=[TensorBoard_callback_Train_History, MLLCallbacks()],\n",
        ")\n",
        "# Get best Model after Training\n",
        "model = tf.keras.models.load_model(\n",
        "    TensorBoard_Log_Train_History_PATH + \"/Best_model.h5\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnDkNI-ELotn"
      },
      "source": [
        "# 10. Start Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "XNdcrJstLoto",
        "outputId": "6138467d-b298-47fe-8a38-9562168a1854"
      },
      "outputs": [],
      "source": [
        "#cd Z:\\Programmierung_NN\n",
        "#tensorboard --logdir=logs/NACHNAME/\n",
        "\n",
        "if IN_COLAB:\n",
        "    %load_ext tensorboard\n",
        "    %tensorboard --logdir logs/$deinNachname/\n",
        "else:\n",
        "    Command='start cmd /k \"Z: & cd Z:\\Programmierung_NN & tensorboard --logdir=logs/'+DeinNachname+'/\"'\n",
        "    os.system(Command)\n",
        "\n",
        "#Öffne http://localhost:6006/ in deinem Browser wenn nicht in colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDWKYUrZLoto"
      },
      "source": [
        "# 11. Export als tf.lite Modell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzLSkZOlLoto",
        "outputId": "0ac50cd4-28fc-4316-c88a-197a3f6ea715"
      },
      "outputs": [],
      "source": [
        "# falls der Kernel mal abstürzen sollte:\n",
        "# model = tf.keras.models.load_model(Pfad der log datei)\n",
        "\n",
        "if IN_COLAB:\n",
        "    Lite_model_file_name = f\"/content/MLL-Netz_{DeinNachname}\"\n",
        "    model_file_path = f\"/content/{DeinNachname}\"\n",
        "else:\n",
        "    Lite_model_file_name = f\"Z:/Netze/MLL-Netz_{DeinNachname}\"\n",
        "    model_file_path = f\"Z:/Netze/{DeinNachname}\"\n",
        "\n",
        "# save models\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(\n",
        "    model\n",
        ")  # hier den Modellobjektnamen eintragen\n",
        "tflite_model = converter.convert()\n",
        "open(Lite_model_file_name + \".tflite\", \"wb\").write(tflite_model)\n",
        "tf.keras.models.save_model(model, f\"{DeinNachname}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 12. Download der trainierten Modelle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "zeR137OIgKjS",
        "outputId": "9fc2b76c-2b77-4e26-e246-ea6242d7fd61"
      },
      "outputs": [],
      "source": [
        "# Download models to local machine, only necessary if in colab\n",
        "if IN_COLAB:\n",
        "    from google.colab import files\n",
        "    # Compress model for download\n",
        "    !tar -czvf model.tar.gz $DeinNachname\n",
        "    files.download('model.tar.gz')\n",
        "    files.download(Lite_model_file_name + '.tflite')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "f701b6929a839fa417ceb7454ef4bfcbf51ba2477385a82ceb157f8da4252d35"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
